# Hitos y pasos a seguir

## Hito 1: Desplegar airflow en un docker

### Crear una imagen de docker para airflow

### Desplegar con docker-compose la imagen

### Crear un job de python que consiga obtener el json

## Milestone 2: Extract, Transform and load in Postgresql

* **AWS S3**: Obtain the data ingested in Milestone 1
* **AWS Glue**:  Apply  Glue Jobs to extract, select and partition data in parquet
* **AWS Athena**: Join and clean information into Postgresql
* Use a Glue Job to ingest that table into postgresql
